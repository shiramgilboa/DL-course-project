{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ybetOARJZoY",
        "outputId": "c6b86198-6c77-4ba2-87d2-2c90f4f24474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rtdl\n",
            "  Downloading rtdl-0.0.13-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: torch<2,>=1.7 in /usr/local/lib/python3.8/dist-packages (from rtdl) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy<2,>=1.18 in /usr/local/lib/python3.8/dist-packages (from rtdl) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2,>=1.7->rtdl) (4.4.0)\n",
            "Installing collected packages: rtdl\n",
            "Successfully installed rtdl-0.0.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libzero==0.0.4\n",
            "  Downloading libzero-0.0.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from libzero==0.0.4) (4.64.1)\n",
            "Collecting pynvml<9,>=8.0\n",
            "  Downloading pynvml-8.0.4-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: torch<2,>=1.6 in /usr/local/lib/python3.8/dist-packages (from libzero==0.0.4) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy<2,>=1.17 in /usr/local/lib/python3.8/dist-packages (from libzero==0.0.4) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2,>=1.6->libzero==0.0.4) (4.4.0)\n",
            "Installing collected packages: pynvml, libzero\n",
            "Successfully installed libzero-0.0.4 pynvml-8.0.4\n"
          ]
        }
      ],
      "source": [
        "# Requirements:\n",
        "!pip install rtdl\n",
        "!pip install libzero==0.0.4"
      ],
      "id": "_ybetOARJZoY"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8UiItfjuJZob"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "\n",
        "import numpy as np\n",
        "import rtdl\n",
        "# rtdl Paper: https://arxiv.org/pdf/2106.11959.pdf\n",
        "import scipy.special\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import zero"
      ],
      "id": "8UiItfjuJZob"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmL7oQgJZoc",
        "outputId": "a9687815-9bce-4f2b-f3ba-2115be6ee7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0')\n",
        "# Docs: https://yura52.github.io/delu/0.0.4/reference/api/zero.improve_reproducibility.html\n",
        "zero.improve_reproducibility(seed=123456)\n",
        "print(device)"
      ],
      "id": "eQmL7oQgJZoc"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "# Upload preprocessed_data.csv\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "5ulM975GWHHK",
        "outputId": "c501f81b-ba64-42a6-e48e-34a70eee6b5f"
      },
      "id": "5ulM975GWHHK",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-602ae30d-613d-4bc5-9e19-f6dfa552a6d7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-602ae30d-613d-4bc5-9e19-f6dfa552a6d7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving preprocessed_data.csv to preprocessed_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('preprocessed_data.csv')\n",
        "labels = df[\"DIED\"]\n",
        "df.drop(\"DIED\",inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "NMnMc_nIZ-Av"
      },
      "id": "NMnMc_nIZ-Av",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Packages and helpers\n"
      ],
      "metadata": {
        "id": "c8fxlYIWdpvn"
      },
      "id": "c8fxlYIWdpvn"
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Packages =======\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.core.frame import DataFrame\n",
        "import seaborn as sns\n",
        "import sklearn as sk\n",
        "from prettytable import PrettyTable\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---- data manipulators ----\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# ---- evaluation ------\n",
        "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, recall_score, precision_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# ====== Functions =======\n",
        "def model_evaluation(y_true, y_pred):\n",
        "    \"\"\"Evaluate the ML model according to different metrics\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    y_true: Data structure containing the true labels of the examples\n",
        "    y_pred: Data structure containing the prediction of the ML model\n",
        "\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    None\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    metric_table = PrettyTable()\n",
        "    metric_table.field_names = ['Metric', 'Score']\n",
        "    metric_table.add_row(['accuracy', accuracy_score(y_true, y_pred)])\n",
        "    metric_table.add_row(['recall', recall_score(y_true, y_pred)])\n",
        "    metric_table.add_row(['presicion', precision_score(y_true, y_pred)])\n",
        "    metric_table.add_row(['f1 score', f1_score(y_true, y_pred)])\n",
        "    metric_table.add_row(['f_beta score', fbeta_score(y_true, y_pred, beta=2)]) # recall is more important\n",
        "    \n",
        "    print(metric_table)\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred))\n",
        "    disp.plot()\n",
        "    disp.ax_.set_xticklabels(['negative','positive'])\n",
        "    disp.ax_.set_yticklabels(['negative','positive'])\n",
        "\n",
        "\n",
        "def data_split(dataset:DataFrame ,n_splits=1, test_size=0.2, train_size=0.8):\n",
        "    \"\"\" split the data into train and test (or train and validation)\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    dataset: A pandas Dataframe to split\n",
        "    n_splits: (optional) An integer of number of splits\n",
        "    test_size: (optional) An inegeger for the propotion of the test set\n",
        "    train_size: (optional) An inegeger for the propotion of the train set\n",
        "\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \n",
        "    X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    spliter = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, train_size=train_size)\n",
        "    X = dataset.drop(dataset.columns[-1], axis=1)\n",
        "    y = dataset[dataset.columns[-1]]\n",
        "    train_index, test_index = next(spliter.split(X, y))\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test\n",
        "    \n",
        "\n",
        "def up_down_sampling(X_train: DataFrame, y_train: DataFrame, ratio: int, up: bool):\n",
        "    \"\"\"up/down sample a dataset\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X_train: A pandas DataFrame of the the train data without the labels\n",
        "    y_train: A pandas DataFrame of the labels of the training data\n",
        "    ratio: An integer for seting the proportion on the minority related to the majority\n",
        "    up: A bool determine up sampling or down sampling\n",
        "    \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    The upsampled X_train and y_train\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    X = pd.concat([X_train, y_train], axis=1)\n",
        "    \n",
        "    # Separate minority and majority classes (assume minority is labeled as 1)\n",
        "    negative_samples = X[X[X.columns[-1]]==0]\n",
        "    positive_samples = X[X[X.columns[-1]]==1]\n",
        "\n",
        "    # Upsample the minotiry class\n",
        "    if up:\n",
        "        upsampled_positive_samples = resample(positive_samples, replace=True, n_samples=int(len(negative_samples)*ratio), random_state=27)\n",
        "        X = pd.concat([negative_samples, upsampled_positive_samples])\n",
        "    # Downsample the majority class\n",
        "    else:\n",
        "        downsampled_negative_samples = resample(negative_samples, replace=True, n_samples=int(len(positive_samples)*ratio), random_state=27)\n",
        "        X = pd.concat([positive_samples, downsampled_negative_samples])\n",
        "\n",
        "    X_train, y_train = X.drop(X.columns[-1], axis=1), X[X.columns[-1]]\n",
        "\n",
        "    return X_train, y_train\n"
      ],
      "metadata": {
        "id": "8_mW72lCK1Sp"
      },
      "id": "8_mW72lCK1Sp",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcTUnE5hJZod"
      },
      "source": [
        "## Data"
      ],
      "id": "TcTUnE5hJZod"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note: Need to choose between original, upsampled and downsampled dataframes using the data_type variable"
      ],
      "metadata": {
        "id": "K0hUpXEHnAjP"
      },
      "id": "K0hUpXEHnAjP"
    },
    {
      "cell_type": "code",
      "source": [
        "# d_train,label_train, d_test,label_test = data_split(df ,n_splits=1, test_size=0.4, train_size=0.6)\n",
        "X_all_up, y_all_up = up_down_sampling(df.__deepcopy__(), labels.__deepcopy__(), ratio=1, up=True)\n",
        "X_all_down, y_all_down = up_down_sampling(df.__deepcopy__(), labels.__deepcopy__(), ratio=1, up=False)"
      ],
      "metadata": {
        "id": "0heqy0bXgC9J"
      },
      "id": "0heqy0bXgC9J",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "6muUgWVGJZoe"
      },
      "outputs": [],
      "source": [
        "# !!! NOTE !!! The dataset splits, preprocessing and other details are\n",
        "# significantly different from those used in the\n",
        "# paper \"Revisiting Deep Learning Models for Tabular Data\",\n",
        "# so the results will be different from the reported in the paper.\n",
        "\n",
        "task_type = 'binclass'\n",
        "assert task_type in ['binclass', 'multiclass', 'regression']\n",
        "\n",
        "data_type = 'downsampled'\n",
        "assert data_type in ['original', 'upsampled', 'downsampled']\n",
        "\n",
        "if data_type == 'original':\n",
        "  X_all = df.astype('float32')\n",
        "  y_all = labels.astype('float32' if task_type == 'regression' else 'int64')\n",
        "\n",
        "if data_type == 'upsampled':\n",
        "  X_all = X_all_up.astype('float32')\n",
        "  y_all = y_all_up.astype('float32' if task_type == 'regression' else 'int64')\n",
        "if data_type == 'downsampled':\n",
        "  X_all = X_all_down.astype('float32')\n",
        "  y_all = y_all_down.astype('float32' if task_type == 'regression' else 'int64')\n",
        "\n",
        "if task_type != 'regression':\n",
        "    y_all = sklearn.preprocessing.LabelEncoder().fit_transform(y_all).astype('int64')\n",
        "n_classes = int(max(y_all)) + 1 if task_type == 'multiclass' else None\n",
        "\n",
        "X = {}\n",
        "y = {}\n",
        "X['train'], X['test'], y['train'], y['test'] = sklearn.model_selection.train_test_split(\n",
        "    X_all, y_all, train_size=0.8\n",
        ")\n",
        "X['train'], X['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
        "    X['train'], y['train'], train_size=0.8\n",
        ")\n",
        "\n",
        "# not the best way to preprocess features, but enough for the demonstration\n",
        "preprocess = sklearn.preprocessing.StandardScaler().fit(X['train'])\n",
        "X = {\n",
        "    k: torch.tensor(preprocess.transform(v), device=device)\n",
        "    for k, v in X.items()\n",
        "}\n",
        "\n",
        "y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
        "\n",
        "# !!! CRUCIAL for neural networks when solving regression problems !!!\n",
        "if task_type == 'regression':\n",
        "    y_mean = y['train'].mean().item()\n",
        "    y_std = y['train'].std().item()\n",
        "    y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
        "else:\n",
        "    y_std = y_mean = None\n",
        "\n",
        "if task_type != 'multiclass':\n",
        "    y = {k: v.float() for k, v in y.items()}"
      ],
      "id": "6muUgWVGJZoe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hX8m3WlJZof"
      },
      "source": [
        "### Model\n",
        "Carefully read the comments and uncomment the code for the model you want to test."
      ],
      "id": "7hX8m3WlJZof"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ukELg049JZof"
      },
      "outputs": [],
      "source": [
        "d_out = n_classes or 1\n",
        "\n",
        "# model = rtdl.MLP.make_baseline(\n",
        "#     d_in=X_all.shape[1],\n",
        "#     d_layers=[128, 256, 128],\n",
        "#     dropout=0.1,\n",
        "#     d_out=d_out,\n",
        "# )\n",
        "# lr = 0.001\n",
        "# weight_decay = 0.0\n",
        "\n",
        "# model = rtdl.ResNet.make_baseline(\n",
        "#     d_in=X_all.shape[1],\n",
        "#     d_main=128,\n",
        "#     d_intermidiate=256,\n",
        "#     dropout_first=0.2,\n",
        "#     dropout_second=0.0,\n",
        "#     n_blocks=2,\n",
        "#     d_out=d_out,\n",
        "# )\n",
        "# lr = 0.001\n",
        "# weight_decay = 0.0\n",
        "\n",
        "model = rtdl.FTTransformer.make_default(\n",
        "    n_num_features=X_all.shape[1],\n",
        "    cat_cardinalities=None,\n",
        "    last_layer_query_idx=[-1],  # it makes the model faster and does NOT affect its output\n",
        "    d_out=d_out,\n",
        ")\n",
        "\n",
        "# === ABOUT CATEGORICAL FEATURES ===\n",
        "# IF you use MLP, ResNet or any other simple feed-forward model (NOT transformer-based model)\n",
        "# AND there are categorical features\n",
        "# THEN you have to implement a wrapper that handles categorical features.\n",
        "# The example below demonstrates how it can be achieved using rtdl.CategoricalFeatureTokenizer.\n",
        "# ==================================\n",
        "# 1. When you have both numerical and categorical features, you should prepare you data like this:\n",
        "#    (X_num<float32>, X_cat<int64>) instead of X<float32>\n",
        "#    Each column in X_cat should contain values within the range from 0 to <(the number of unique values in column) - 1>;\n",
        "#    use sklean.preprocessing.OrdinalEncoder to achieve this;\n",
        "# 2. Prepare a list of so called \"cardinalities\":\n",
        "#    cardinalities[i] = <the number of unique values of the i-th categorical feature>\n",
        "# 3. See the commented example below and adapt it for your needs.\n",
        "#\n",
        "# class Model(nn.Module):\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         n_num_features: int,\n",
        "#         cat_tokenizer: rtdl.CategoricalFeatureTokenizer,\n",
        "#         mlp_kwargs: Dict[str, Any],\n",
        "#     ):\n",
        "#         super().__init__()\n",
        "#         self.cat_tokenizer = cat_tokenizer\n",
        "#         self.model = rtdl.MLP.make_baseline(\n",
        "#             d_in=n_num_features + cat_tokenizer.n_tokens * cat_tokenizer.d_token,\n",
        "#             **mlp_kwargs,\n",
        "#         )\n",
        "#\n",
        "#     def forward(self, x_num, x_cat):\n",
        "#         return self.model(\n",
        "#             torch.cat([x_num, self.cat_tokenizer(x_cat).flatten(1, -1)], dim=1)\n",
        "#         )\n",
        "#\n",
        "# model = Model(\n",
        "#     # `None` means \"Do not transform numerical features\"\n",
        "#     # `d_token` is the size of embedding for ONE categorical feature\n",
        "#     X_num_all.shape[1],\n",
        "#     rtdl.CategoricalFeatureTokenizer(cardinalities, d_token, True, 'uniform'),\n",
        "#     mlp_kwargs,\n",
        "# )\n",
        "# Then the model should be used as `model(x_num, x_cat)` instead of of `model(x)`.\n",
        "\n",
        "model.to(device)\n",
        "optimizer = (\n",
        "    model.make_default_optimizer()\n",
        "    if isinstance(model, rtdl.FTTransformer)\n",
        "    else torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        ")\n",
        "loss_fn = (\n",
        "    F.binary_cross_entropy_with_logits\n",
        "    if task_type == 'binclass'\n",
        "    else F.cross_entropy\n",
        "    if task_type == 'multiclass'\n",
        "    else F.mse_loss\n",
        ")"
      ],
      "id": "ukELg049JZof"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8_ywaIhJZog"
      },
      "source": [
        "### Training"
      ],
      "id": "q8_ywaIhJZog"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "uHukjzlRJZoh",
        "outputId": "37a887ed-cc88-4aaf-ee40-f393c3646e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+---------------------+\n",
            "|    Metric    |        Score        |\n",
            "+--------------+---------------------+\n",
            "|   accuracy   |  0.4949188378120311 |\n",
            "|    recall    |  0.9811078006500542 |\n",
            "|  presicion   | 0.49925915716205505 |\n",
            "|   f1 score   |  0.6617643700472722 |\n",
            "| f_beta score |  0.822369541280238  |\n",
            "+--------------+---------------------+\n",
            "Test score before training: 0.4949\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def apply_model(x_num, x_cat=None):\n",
        "    if isinstance(model, rtdl.FTTransformer):\n",
        "        return model(x_num, x_cat)\n",
        "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
        "        assert x_cat is None\n",
        "        return model(x_num)\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            f'Looks like you are using a custom model: {type(model)}.'\n",
        "            ' Then you have to implement this branch first.'\n",
        "        )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(part,oureval=False):\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for batch in zero.iter_batches(X[part], 1024):\n",
        "        prediction.append(apply_model(batch))\n",
        "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
        "    target = y[part].cpu().numpy()\n",
        "\n",
        "    if task_type == 'binclass':\n",
        "        prediction = np.round(scipy.special.expit(prediction))\n",
        "        if oureval:\n",
        "          model_evaluation(target, prediction) # our evaluator\n",
        "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
        "    elif task_type == 'multiclass':\n",
        "        prediction = prediction.argmax(1)\n",
        "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
        "    else:\n",
        "        assert task_type == 'regression'\n",
        "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5 * y_std\n",
        "    return score\n",
        "\n",
        "\n",
        "# Create a dataloader for batches of indices\n",
        "# Docs: https://yura52.github.io/delu/reference/api/zero.data.IndexLoader.html\n",
        "batch_size = 256\n",
        "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
        "\n",
        "# Create a progress tracker for early stopping\n",
        "# Docs: https://yura52.github.io/delu/reference/api/zero.ProgressTracker.html\n",
        "progress = zero.ProgressTracker(patience=100)\n",
        "\n",
        "print(f'Test score before training: {evaluate(\"test\",True):.4f}')"
      ],
      "id": "uHukjzlRJZoh"
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6XWclEsJZoh",
        "outputId": "28f4a446-b75f-41cb-9a65-058e18eb77d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch) 1 (batch) 0 (loss) 0.7176\n",
            "(epoch) 1 (batch) 73 (loss) 0.2389\n",
            "(epoch) 1 (batch) 146 (loss) 0.2858\n",
            "(epoch) 1 (batch) 219 (loss) 0.2376\n",
            "(epoch) 1 (batch) 292 (loss) 0.2152\n",
            "(epoch) 1 (batch) 365 (loss) 0.2404\n",
            "Epoch 001 | Validation score: 0.9144 | Test score: 0.9098 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 2 (batch) 0 (loss) 0.2309\n",
            "(epoch) 2 (batch) 73 (loss) 0.2083\n",
            "(epoch) 2 (batch) 146 (loss) 0.2923\n",
            "(epoch) 2 (batch) 219 (loss) 0.2291\n",
            "(epoch) 2 (batch) 292 (loss) 0.2105\n",
            "(epoch) 2 (batch) 365 (loss) 0.2307\n",
            "Epoch 002 | Validation score: 0.9138 | Test score: 0.9097\n",
            "(epoch) 3 (batch) 0 (loss) 0.2295\n",
            "(epoch) 3 (batch) 73 (loss) 0.2018\n",
            "(epoch) 3 (batch) 146 (loss) 0.2915\n",
            "(epoch) 3 (batch) 219 (loss) 0.2351\n",
            "(epoch) 3 (batch) 292 (loss) 0.2144\n",
            "(epoch) 3 (batch) 365 (loss) 0.2315\n",
            "Epoch 003 | Validation score: 0.9141 | Test score: 0.9095\n",
            "(epoch) 4 (batch) 0 (loss) 0.2276\n",
            "(epoch) 4 (batch) 73 (loss) 0.2006\n",
            "(epoch) 4 (batch) 146 (loss) 0.2975\n",
            "(epoch) 4 (batch) 219 (loss) 0.2367\n",
            "(epoch) 4 (batch) 292 (loss) 0.2178\n",
            "(epoch) 4 (batch) 365 (loss) 0.2246\n",
            "Epoch 004 | Validation score: 0.9151 | Test score: 0.9105 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 5 (batch) 0 (loss) 0.2246\n",
            "(epoch) 5 (batch) 73 (loss) 0.1994\n",
            "(epoch) 5 (batch) 146 (loss) 0.2944\n",
            "(epoch) 5 (batch) 219 (loss) 0.2369\n",
            "(epoch) 5 (batch) 292 (loss) 0.2136\n",
            "(epoch) 5 (batch) 365 (loss) 0.2257\n",
            "Epoch 005 | Validation score: 0.9153 | Test score: 0.9101 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 6 (batch) 0 (loss) 0.2263\n",
            "(epoch) 6 (batch) 73 (loss) 0.2027\n",
            "(epoch) 6 (batch) 146 (loss) 0.2897\n",
            "(epoch) 6 (batch) 219 (loss) 0.2359\n",
            "(epoch) 6 (batch) 292 (loss) 0.2184\n",
            "(epoch) 6 (batch) 365 (loss) 0.2245\n",
            "Epoch 006 | Validation score: 0.9154 | Test score: 0.9098 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 7 (batch) 0 (loss) 0.2225\n",
            "(epoch) 7 (batch) 73 (loss) 0.1967\n",
            "(epoch) 7 (batch) 146 (loss) 0.2882\n",
            "(epoch) 7 (batch) 219 (loss) 0.2368\n",
            "(epoch) 7 (batch) 292 (loss) 0.2123\n",
            "(epoch) 7 (batch) 365 (loss) 0.2191\n",
            "Epoch 007 | Validation score: 0.9154 | Test score: 0.9100\n",
            "(epoch) 8 (batch) 0 (loss) 0.2276\n",
            "(epoch) 8 (batch) 73 (loss) 0.2005\n",
            "(epoch) 8 (batch) 146 (loss) 0.2954\n",
            "(epoch) 8 (batch) 219 (loss) 0.2327\n",
            "(epoch) 8 (batch) 292 (loss) 0.2095\n",
            "(epoch) 8 (batch) 365 (loss) 0.2248\n",
            "Epoch 008 | Validation score: 0.9155 | Test score: 0.9105 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 9 (batch) 0 (loss) 0.2214\n",
            "(epoch) 9 (batch) 73 (loss) 0.1985\n",
            "(epoch) 9 (batch) 146 (loss) 0.2905\n",
            "(epoch) 9 (batch) 219 (loss) 0.2328\n",
            "(epoch) 9 (batch) 292 (loss) 0.2128\n",
            "(epoch) 9 (batch) 365 (loss) 0.2222\n",
            "Epoch 009 | Validation score: 0.9153 | Test score: 0.9099\n",
            "(epoch) 10 (batch) 0 (loss) 0.2228\n",
            "(epoch) 10 (batch) 73 (loss) 0.2010\n",
            "(epoch) 10 (batch) 146 (loss) 0.2951\n",
            "(epoch) 10 (batch) 219 (loss) 0.2356\n",
            "(epoch) 10 (batch) 292 (loss) 0.2121\n",
            "(epoch) 10 (batch) 365 (loss) 0.2203\n",
            "Epoch 010 | Validation score: 0.9157 | Test score: 0.9101 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 11 (batch) 0 (loss) 0.2223\n",
            "(epoch) 11 (batch) 73 (loss) 0.2018\n",
            "(epoch) 11 (batch) 146 (loss) 0.2913\n",
            "(epoch) 11 (batch) 219 (loss) 0.2343\n",
            "(epoch) 11 (batch) 292 (loss) 0.2145\n",
            "(epoch) 11 (batch) 365 (loss) 0.2228\n",
            "Epoch 011 | Validation score: 0.9157 | Test score: 0.9102\n",
            "(epoch) 12 (batch) 0 (loss) 0.2271\n",
            "(epoch) 12 (batch) 73 (loss) 0.2000\n",
            "(epoch) 12 (batch) 146 (loss) 0.2888\n",
            "(epoch) 12 (batch) 219 (loss) 0.2378\n",
            "(epoch) 12 (batch) 292 (loss) 0.2128\n",
            "(epoch) 12 (batch) 365 (loss) 0.2163\n",
            "Epoch 012 | Validation score: 0.9156 | Test score: 0.9103\n",
            "(epoch) 13 (batch) 0 (loss) 0.2264\n",
            "(epoch) 13 (batch) 73 (loss) 0.1990\n",
            "(epoch) 13 (batch) 146 (loss) 0.2916\n",
            "(epoch) 13 (batch) 219 (loss) 0.2346\n",
            "(epoch) 13 (batch) 292 (loss) 0.2139\n",
            "(epoch) 13 (batch) 365 (loss) 0.2185\n",
            "Epoch 013 | Validation score: 0.9155 | Test score: 0.9101\n",
            "(epoch) 14 (batch) 0 (loss) 0.2269\n",
            "(epoch) 14 (batch) 73 (loss) 0.1970\n",
            "(epoch) 14 (batch) 146 (loss) 0.2894\n",
            "(epoch) 14 (batch) 219 (loss) 0.2373\n",
            "(epoch) 14 (batch) 292 (loss) 0.2108\n",
            "(epoch) 14 (batch) 365 (loss) 0.2249\n",
            "Epoch 014 | Validation score: 0.9153 | Test score: 0.9102\n",
            "(epoch) 15 (batch) 0 (loss) 0.2225\n",
            "(epoch) 15 (batch) 73 (loss) 0.1991\n",
            "(epoch) 15 (batch) 146 (loss) 0.2887\n",
            "(epoch) 15 (batch) 219 (loss) 0.2362\n",
            "(epoch) 15 (batch) 292 (loss) 0.2127\n",
            "(epoch) 15 (batch) 365 (loss) 0.2179\n",
            "Epoch 015 | Validation score: 0.9157 | Test score: 0.9106\n",
            "(epoch) 16 (batch) 0 (loss) 0.2239\n",
            "(epoch) 16 (batch) 73 (loss) 0.2012\n",
            "(epoch) 16 (batch) 146 (loss) 0.2974\n",
            "(epoch) 16 (batch) 219 (loss) 0.2327\n",
            "(epoch) 16 (batch) 292 (loss) 0.2116\n",
            "(epoch) 16 (batch) 365 (loss) 0.2217\n",
            "Epoch 016 | Validation score: 0.9156 | Test score: 0.9101\n",
            "(epoch) 17 (batch) 0 (loss) 0.2215\n",
            "(epoch) 17 (batch) 73 (loss) 0.2005\n",
            "(epoch) 17 (batch) 146 (loss) 0.2934\n",
            "(epoch) 17 (batch) 219 (loss) 0.2317\n",
            "(epoch) 17 (batch) 292 (loss) 0.2126\n",
            "(epoch) 17 (batch) 365 (loss) 0.2201\n",
            "Epoch 017 | Validation score: 0.9160 | Test score: 0.9108 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 18 (batch) 0 (loss) 0.2241\n",
            "(epoch) 18 (batch) 73 (loss) 0.1980\n",
            "(epoch) 18 (batch) 146 (loss) 0.2896\n",
            "(epoch) 18 (batch) 219 (loss) 0.2339\n",
            "(epoch) 18 (batch) 292 (loss) 0.2112\n",
            "(epoch) 18 (batch) 365 (loss) 0.2173\n",
            "Epoch 018 | Validation score: 0.9155 | Test score: 0.9101\n",
            "(epoch) 19 (batch) 0 (loss) 0.2255\n",
            "(epoch) 19 (batch) 73 (loss) 0.1996\n",
            "(epoch) 19 (batch) 146 (loss) 0.2938\n",
            "(epoch) 19 (batch) 219 (loss) 0.2291\n",
            "(epoch) 19 (batch) 292 (loss) 0.2127\n",
            "(epoch) 19 (batch) 365 (loss) 0.2194\n",
            "Epoch 019 | Validation score: 0.9157 | Test score: 0.9099\n",
            "(epoch) 20 (batch) 0 (loss) 0.2244\n",
            "(epoch) 20 (batch) 73 (loss) 0.1996\n",
            "(epoch) 20 (batch) 146 (loss) 0.2951\n",
            "(epoch) 20 (batch) 219 (loss) 0.2344\n",
            "(epoch) 20 (batch) 292 (loss) 0.2112\n",
            "(epoch) 20 (batch) 365 (loss) 0.2199\n",
            "Epoch 020 | Validation score: 0.9163 | Test score: 0.9105 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 21 (batch) 0 (loss) 0.2241\n",
            "(epoch) 21 (batch) 73 (loss) 0.2024\n",
            "(epoch) 21 (batch) 146 (loss) 0.2917\n",
            "(epoch) 21 (batch) 219 (loss) 0.2351\n",
            "(epoch) 21 (batch) 292 (loss) 0.2056\n",
            "(epoch) 21 (batch) 365 (loss) 0.2158\n",
            "Epoch 021 | Validation score: 0.9153 | Test score: 0.9099\n",
            "(epoch) 22 (batch) 0 (loss) 0.2230\n",
            "(epoch) 22 (batch) 73 (loss) 0.2014\n",
            "(epoch) 22 (batch) 146 (loss) 0.2963\n",
            "(epoch) 22 (batch) 219 (loss) 0.2313\n",
            "(epoch) 22 (batch) 292 (loss) 0.2135\n",
            "(epoch) 22 (batch) 365 (loss) 0.2176\n",
            "Epoch 022 | Validation score: 0.9150 | Test score: 0.9095\n",
            "(epoch) 23 (batch) 0 (loss) 0.2300\n",
            "(epoch) 23 (batch) 73 (loss) 0.1992\n",
            "(epoch) 23 (batch) 146 (loss) 0.2886\n",
            "(epoch) 23 (batch) 219 (loss) 0.2314\n",
            "(epoch) 23 (batch) 292 (loss) 0.2096\n",
            "(epoch) 23 (batch) 365 (loss) 0.2185\n",
            "Epoch 023 | Validation score: 0.9153 | Test score: 0.9107\n",
            "(epoch) 24 (batch) 0 (loss) 0.2281\n",
            "(epoch) 24 (batch) 73 (loss) 0.2011\n",
            "(epoch) 24 (batch) 146 (loss) 0.2881\n",
            "(epoch) 24 (batch) 219 (loss) 0.2290\n",
            "(epoch) 24 (batch) 292 (loss) 0.2079\n",
            "(epoch) 24 (batch) 365 (loss) 0.2158\n",
            "Epoch 024 | Validation score: 0.9154 | Test score: 0.9102\n",
            "(epoch) 25 (batch) 0 (loss) 0.2234\n",
            "(epoch) 25 (batch) 73 (loss) 0.2006\n",
            "(epoch) 25 (batch) 146 (loss) 0.2896\n",
            "(epoch) 25 (batch) 219 (loss) 0.2298\n",
            "(epoch) 25 (batch) 292 (loss) 0.2093\n",
            "(epoch) 25 (batch) 365 (loss) 0.2189\n",
            "Epoch 025 | Validation score: 0.9153 | Test score: 0.9105\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 25\n",
        "prediction = []\n",
        "y_true = []\n",
        "report_frequency = len(X['train']) // batch_size // 5\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    for iteration, batch_idx in enumerate(train_loader):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        x_batch = X['train'][batch_idx]\n",
        "        y_batch = y['train'][batch_idx]\n",
        "        predicted_batch = apply_model(x_batch).squeeze(1)\n",
        "        loss = loss_fn(predicted_batch, y_batch)        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if iteration % report_frequency == 0:\n",
        "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
        "\n",
        "    val_score = evaluate('val')\n",
        "    test_score = evaluate('test')\n",
        "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
        "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
        "    if progress.success:\n",
        "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
        "    print()\n",
        "    if progress.fail:\n",
        "        print(\"Early stopping due to progress fail\")\n",
        "        break"
      ],
      "id": "i6XWclEsJZoh"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{data_type} data results {evaluate(\"test\",True):.4f}')"
      ],
      "metadata": {
        "id": "piYLqga73vSl"
      },
      "id": "piYLqga73vSl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}